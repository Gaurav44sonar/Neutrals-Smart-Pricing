{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Base Price</th>\n",
       "      <th>Competitor Price</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Supply</th>\n",
       "      <th>Expiry Days</th>\n",
       "      <th>Optimized Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kinder Joy</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bru Coffee 200g</td>\n",
       "      <td>437</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bournvita 500g</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy Milk Chocolate</td>\n",
       "      <td>144</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amul Milk 1L</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product Name  Base Price  Competitor Price  Demand  Supply  \\\n",
       "0            Kinder Joy         114               114       1       0   \n",
       "1       Bru Coffee 200g         437               449       0       1   \n",
       "2        Bournvita 500g         125               126       2       1   \n",
       "3  Dairy Milk Chocolate         144               148       0       1   \n",
       "4          Amul Milk 1L          66                65       2       1   \n",
       "\n",
       "   Expiry Days  Optimized Price  \n",
       "0           16              112  \n",
       "1           27              429  \n",
       "2           18              123  \n",
       "3           15              137  \n",
       "4           12               63  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"blinkit_dynamic_pricing_1000_samples.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product Name        0\n",
       "Base Price          0\n",
       "Competitor Price    0\n",
       "Demand              0\n",
       "Supply              0\n",
       "Expiry Days         0\n",
       "Optimized Price     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# df[\"Demand\"] = encoder.fit_transform(df[\"Demand\"])  # Convert 'High', 'Medium', 'Low' → 2,1,0\n",
    "# df[\"Supply\"] = encoder.fit_transform(df[\"Supply\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Base Price</th>\n",
       "      <th>Competitor Price</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Supply</th>\n",
       "      <th>Expiry Days</th>\n",
       "      <th>Optimized Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kinder Joy</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bru Coffee 200g</td>\n",
       "      <td>437</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bournvita 500g</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy Milk Chocolate</td>\n",
       "      <td>144</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amul Milk 1L</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product Name  Base Price  Competitor Price  Demand  Supply  \\\n",
       "0            Kinder Joy         114               114       1       0   \n",
       "1       Bru Coffee 200g         437               449       0       1   \n",
       "2        Bournvita 500g         125               126       2       1   \n",
       "3  Dairy Milk Chocolate         144               148       0       1   \n",
       "4          Amul Milk 1L          66                65       2       1   \n",
       "\n",
       "   Expiry Days  Optimized Price  \n",
       "0           16              112  \n",
       "1           27              429  \n",
       "2           18              123  \n",
       "3           15              137  \n",
       "4           12               63  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.93175329054999"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R² Score: 0.9999\n",
      "Testing R² Score: 0.9993\n"
     ]
    }
   ],
   "source": [
    "train_score = rf_model.score(X_train, y_train)  # R² score on training set\n",
    "test_score = rf_model.score(X_test, y_test)  # R² score on test set\n",
    "\n",
    "print(f\"Training R² Score: {train_score:.4f}\")\n",
    "print(f\"Testing R² Score: {test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([485.295])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=rf_model.predict([[125,126,2,1,18]])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(1,200):\n",
    "    rf=RandomForestRegressor(n_estimators=i,random_state=42)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    l.append(r2_score(y_test,y_pred)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.93246344195582"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssona\\AppData\\Local\\Temp\\ipykernel_2084\\1203688443.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.18602289  1.28504238  0.08144352 -0.3197561  -0.72095571  1.55250879\n",
      " -0.72095571 -1.25588854  1.15130917 -0.72095571  1.41877558  0.34890993\n",
      "  1.01757597 -0.72095571 -0.72095571 -0.3197561   1.28504238  0.75010955\n",
      " -0.72095571  0.61637635 -1.12215533 -1.25588854  1.41877558 -1.12215533\n",
      "  0.88384276  0.21517673 -1.12215533  1.01757597  0.34890993  1.41877558\n",
      " -0.58722251  1.686242   -0.58722251 -1.12215533  0.88384276 -0.85468892\n",
      "  1.686242    0.75010955 -0.98842213 -1.65708816  1.41877558  0.21517673\n",
      "  1.686242   -0.98842213  0.75010955  0.34890993  0.08144352  0.88384276\n",
      " -0.58722251 -0.4534893   1.41877558  0.88384276 -1.65708816 -1.25588854\n",
      " -0.05228968 -0.4534893   0.61637635  0.34890993  0.88384276 -1.25588854\n",
      "  1.15130917 -1.38962175  1.686242   -1.65708816  1.15130917 -1.52335495\n",
      "  0.21517673 -0.98842213  0.21517673  1.41877558  0.61637635 -1.12215533\n",
      " -0.18602289 -0.3197561  -0.18602289  0.21517673 -0.98842213 -1.38962175\n",
      "  1.28504238 -1.25588854  0.48264314 -0.72095571 -0.05228968  1.41877558\n",
      "  0.48264314  1.41877558  1.41877558 -0.58722251 -1.25588854 -0.18602289\n",
      "  1.28504238 -0.3197561  -0.05228968  1.28504238  1.15130917 -0.72095571\n",
      "  0.08144352  0.61637635  1.15130917  1.28504238  0.75010955 -1.65708816\n",
      " -0.3197561  -1.52335495  1.28504238 -1.52335495  0.88384276  0.34890993\n",
      " -1.52335495  1.01757597  1.15130917  0.75010955 -1.12215533  0.88384276\n",
      " -1.12215533  0.75010955  0.48264314 -0.3197561   0.08144352 -0.85468892\n",
      "  1.55250879  0.48264314 -0.98842213  0.75010955  0.21517673 -1.65708816\n",
      "  0.48264314 -1.25588854  0.21517673  0.61637635 -0.4534893   0.08144352\n",
      "  1.28504238  0.34890993  1.15130917 -1.38962175  1.15130917  1.686242\n",
      " -0.98842213 -1.52335495 -0.18602289  0.48264314 -0.18602289  0.48264314\n",
      " -0.4534893   1.15130917  1.28504238 -1.52335495 -1.38962175 -1.38962175\n",
      "  0.88384276 -0.85468892 -1.38962175  0.08144352  0.21517673 -1.65708816\n",
      " -0.85468892 -1.12215533 -0.98842213  0.88384276 -0.3197561  -0.98842213\n",
      "  1.686242   -0.58722251  1.41877558 -1.25588854 -0.4534893  -1.52335495\n",
      "  1.686242   -0.3197561   1.28504238  0.21517673  0.21517673  1.01757597\n",
      "  0.08144352 -0.98842213  1.41877558 -1.65708816  0.21517673 -0.3197561\n",
      " -0.72095571  0.48264314 -0.18602289  1.15130917  0.88384276  1.01757597\n",
      " -0.18602289  0.34890993 -0.18602289 -0.05228968 -0.3197561   1.41877558\n",
      " -0.4534893  -0.4534893  -0.98842213  1.15130917  1.28504238  0.61637635\n",
      " -1.38962175  1.01757597  0.75010955 -0.18602289 -0.58722251  1.01757597\n",
      " -0.4534893  -0.05228968 -1.25588854 -0.72095571  1.686242   -0.4534893\n",
      "  1.686242    0.75010955 -1.25588854  0.08144352  1.41877558  0.34890993\n",
      " -0.05228968 -1.65708816  1.41877558 -1.25588854 -0.18602289  1.01757597\n",
      " -0.85468892 -1.38962175  0.34890993  0.48264314  1.15130917 -0.18602289\n",
      " -0.18602289 -1.65708816  1.28504238  1.41877558  1.686242    1.01757597\n",
      " -1.25588854 -0.58722251  0.61637635 -1.38962175 -1.25588854  1.55250879\n",
      "  0.61637635  0.61637635  1.686242   -0.18602289 -0.05228968 -1.38962175\n",
      "  0.88384276  0.48264314 -0.58722251 -1.38962175  1.41877558 -0.3197561\n",
      " -1.52335495  1.28504238 -1.52335495 -1.52335495 -0.18602289  0.48264314\n",
      " -1.65708816 -1.25588854 -0.58722251 -1.12215533 -1.52335495 -1.25588854\n",
      " -0.4534893   0.61637635  1.01757597 -0.18602289  1.01757597  1.55250879\n",
      " -0.4534893  -0.72095571 -0.3197561  -0.18602289 -1.38962175 -0.3197561\n",
      " -0.72095571 -1.52335495  0.21517673 -0.72095571  0.61637635  0.75010955\n",
      "  1.28504238  0.61637635 -0.4534893  -1.52335495 -1.65708816 -0.85468892\n",
      "  1.01757597 -0.98842213 -1.38962175 -1.52335495 -0.98842213 -0.3197561\n",
      "  0.48264314  1.01757597  0.88384276  1.28504238  0.08144352 -1.12215533\n",
      "  1.15130917  0.08144352 -1.12215533  0.48264314  0.61637635 -0.05228968\n",
      "  0.21517673 -0.58722251  0.08144352  0.48264314 -0.3197561  -1.25588854\n",
      "  0.34890993  1.41877558 -0.4534893  -0.05228968  0.21517673  0.48264314\n",
      "  1.686242    1.28504238 -1.65708816  1.41877558  1.41877558  0.48264314\n",
      " -0.98842213 -0.72095571 -0.98842213  1.41877558  0.48264314 -0.05228968\n",
      "  1.15130917  0.34890993 -1.52335495 -0.4534893   0.88384276 -0.18602289\n",
      " -0.72095571 -0.85468892  0.88384276 -1.12215533 -0.58722251  0.61637635\n",
      "  1.01757597  1.15130917  0.61637635 -0.3197561  -1.52335495 -1.38962175\n",
      "  0.88384276  0.08144352  1.55250879  0.34890993 -0.85468892 -1.38962175\n",
      "  0.21517673  1.15130917  1.686242   -0.4534893   1.55250879  1.55250879\n",
      " -0.18602289  1.686242   -1.12215533 -1.25588854 -0.58722251  1.15130917\n",
      "  0.61637635  1.01757597 -0.98842213 -0.05228968  0.61637635 -0.98842213\n",
      "  1.686242    0.48264314  1.01757597 -0.05228968 -0.18602289  1.28504238\n",
      " -0.58722251  1.686242   -0.98842213 -0.58722251 -0.98842213 -1.12215533\n",
      " -1.12215533 -0.98842213 -1.65708816 -0.98842213  0.08144352 -0.18602289\n",
      "  1.41877558  0.48264314 -0.4534893   1.41877558 -0.4534893  -1.65708816\n",
      " -1.52335495  0.88384276 -0.3197561   1.686242   -1.38962175  0.34890993\n",
      " -0.85468892  1.01757597  0.75010955 -0.3197561   0.75010955  1.15130917\n",
      " -1.25588854  0.88384276 -0.18602289  0.88384276  1.15130917  1.15130917\n",
      "  1.686242   -1.38962175 -1.65708816 -0.05228968  1.15130917 -1.52335495\n",
      "  1.686242   -1.25588854 -0.98842213 -1.65708816 -0.05228968 -1.25588854\n",
      " -0.4534893  -1.12215533 -1.12215533  0.08144352  0.75010955 -1.52335495\n",
      "  0.75010955  0.75010955  0.61637635  1.28504238 -0.58722251 -0.58722251\n",
      "  1.55250879  0.48264314 -0.85468892  1.55250879 -0.72095571 -1.12215533\n",
      "  0.61637635  0.21517673 -0.18602289 -0.4534893   0.34890993 -1.52335495\n",
      " -0.3197561   0.48264314 -1.12215533  0.88384276 -0.4534893   0.48264314\n",
      "  0.48264314 -1.52335495 -0.58722251 -0.4534893  -1.25588854 -1.12215533\n",
      " -0.85468892 -0.4534893   1.15130917  1.41877558 -1.52335495  0.34890993\n",
      "  0.61637635  1.15130917 -1.12215533  0.48264314 -0.3197561   0.88384276\n",
      " -0.4534893   0.88384276 -1.52335495  0.21517673 -1.12215533  0.21517673\n",
      " -1.38962175  0.48264314  0.21517673  1.28504238  0.48264314 -1.65708816\n",
      " -0.3197561  -1.52335495 -1.65708816  0.75010955 -1.38962175 -0.85468892\n",
      " -0.05228968  0.61637635 -0.85468892  1.28504238 -0.18602289 -0.4534893\n",
      "  1.686242    1.686242   -0.18602289  1.686242    1.15130917 -0.98842213\n",
      " -1.38962175  0.34890993 -0.85468892  0.34890993 -0.98842213  0.75010955\n",
      "  1.55250879 -0.18602289 -0.05228968  1.28504238  1.55250879  0.48264314\n",
      "  0.08144352  0.48264314  1.15130917  0.21517673  0.08144352 -0.98842213\n",
      "  1.55250879  1.15130917  1.28504238 -0.05228968  0.48264314 -0.58722251\n",
      "  0.75010955  0.34890993  1.55250879  1.15130917  0.61637635 -1.52335495\n",
      " -1.65708816  1.28504238 -1.65708816  1.55250879 -0.05228968 -1.25588854\n",
      " -1.25588854 -0.85468892 -1.38962175 -0.4534893   0.34890993  1.55250879\n",
      " -0.85468892  1.15130917 -1.12215533 -0.58722251  1.41877558  0.21517673\n",
      "  0.34890993  0.08144352 -0.3197561   1.15130917 -0.58722251 -0.05228968\n",
      " -0.4534893   1.55250879 -1.52335495 -0.3197561   0.48264314 -0.3197561\n",
      " -1.52335495  1.28504238 -0.58722251  1.55250879 -1.65708816 -0.85468892\n",
      " -0.98842213  0.08144352 -0.05228968 -1.65708816  1.55250879 -0.98842213\n",
      " -1.65708816  0.48264314  1.686242    0.61637635  1.01757597 -1.52335495\n",
      " -0.4534893  -1.65708816  0.34890993 -0.72095571  0.08144352 -0.72095571\n",
      "  0.08144352  1.41877558  0.48264314 -1.52335495 -0.85468892 -0.85468892\n",
      "  0.61637635  1.28504238 -0.72095571 -1.12215533  1.28504238  0.08144352\n",
      " -0.18602289 -1.38962175 -1.25588854 -0.05228968 -0.58722251  0.34890993\n",
      "  0.61637635  1.15130917 -0.05228968  0.21517673  0.75010955 -1.12215533\n",
      " -0.58722251  0.34890993 -1.38962175 -1.12215533 -0.85468892  1.15130917\n",
      "  0.48264314 -1.25588854 -1.52335495 -1.12215533  0.08144352 -0.58722251\n",
      "  0.48264314 -0.58722251  0.21517673 -0.05228968  0.75010955 -0.58722251\n",
      " -0.58722251 -0.18602289 -0.18602289  0.34890993 -0.98842213  0.08144352\n",
      "  1.55250879  1.01757597 -1.25588854 -1.65708816  1.55250879 -1.25588854\n",
      "  1.28504238 -1.25588854 -0.05228968  1.28504238  1.15130917  1.28504238\n",
      "  1.01757597  0.75010955 -0.72095571 -0.05228968 -0.18602289  1.15130917\n",
      " -0.58722251  0.88384276  1.686242   -1.12215533  0.21517673  0.21517673\n",
      "  0.21517673  1.15130917 -0.98842213 -0.18602289  1.01757597  0.48264314\n",
      " -0.4534893   1.15130917 -0.98842213 -0.3197561   1.686242    0.48264314\n",
      "  1.28504238 -1.52335495  1.55250879  0.21517673  1.01757597 -0.58722251\n",
      " -1.12215533 -1.12215533 -1.65708816 -1.52335495 -0.3197561   0.61637635\n",
      "  1.686242    0.48264314 -0.98842213  0.75010955  1.28504238 -1.65708816\n",
      " -1.65708816  1.15130917 -1.12215533  0.08144352  0.08144352  0.21517673\n",
      " -0.18602289  0.34890993 -0.4534893   1.01757597  1.01757597 -0.18602289\n",
      "  1.28504238  0.21517673 -0.05228968  1.55250879 -1.65708816 -0.98842213\n",
      " -0.05228968 -1.25588854  0.75010955 -0.58722251 -1.52335495  0.34890993\n",
      "  0.21517673 -0.05228968  0.34890993 -1.25588854 -0.58722251 -1.25588854\n",
      "  0.61637635  1.01757597  1.686242   -0.98842213  1.01757597  1.686242\n",
      " -0.4534893   0.75010955 -0.85468892  0.61637635  0.48264314  1.15130917\n",
      " -1.52335495  0.34890993 -1.65708816 -1.52335495  0.34890993 -0.85468892\n",
      "  0.34890993  0.34890993  0.21517673 -1.52335495 -0.58722251 -0.72095571\n",
      " -1.65708816 -0.72095571  0.75010955  0.75010955  0.75010955  1.28504238\n",
      "  0.21517673 -0.3197561   0.75010955 -1.65708816  0.61637635  1.15130917\n",
      "  0.34890993 -0.3197561  -0.05228968 -1.38962175 -0.72095571  0.48264314\n",
      "  0.88384276 -1.52335495  0.75010955 -1.65708816  1.28504238  0.48264314\n",
      " -0.05228968  1.41877558  1.41877558  1.686242   -1.52335495 -0.85468892\n",
      "  1.01757597  1.15130917 -1.12215533 -0.3197561  -1.65708816  0.88384276\n",
      " -0.58722251 -0.05228968 -1.25588854 -0.58722251  0.21517673  1.41877558\n",
      "  0.21517673  1.55250879 -0.98842213  0.48264314 -0.72095571  0.08144352\n",
      "  0.34890993  1.686242   -1.52335495  0.08144352  1.41877558  1.41877558\n",
      "  0.48264314  0.34890993 -1.52335495  0.08144352  1.01757597  0.48264314\n",
      " -1.52335495 -0.58722251  1.28504238 -0.98842213  1.55250879  1.686242\n",
      " -0.85468892 -0.72095571 -0.85468892 -1.52335495  0.34890993 -0.85468892\n",
      "  0.61637635 -0.3197561   1.01757597  1.41877558  1.686242    1.55250879\n",
      "  0.88384276  0.08144352  0.21517673  0.34890993  0.21517673 -1.52335495\n",
      "  1.41877558  0.21517673  0.88384276 -0.4534893  -1.52335495 -0.98842213\n",
      "  1.41877558  1.01757597 -0.18602289  0.75010955  0.48264314 -0.05228968\n",
      " -1.12215533  0.08144352  0.48264314 -0.98842213 -1.12215533 -1.65708816\n",
      " -1.38962175  0.61637635  1.15130917  0.61637635 -1.12215533  0.08144352\n",
      " -0.98842213 -0.3197561   0.21517673  1.15130917 -1.12215533  0.88384276\n",
      " -1.65708816  1.686242   -1.12215533 -0.3197561   0.61637635  1.41877558\n",
      " -0.18602289  1.41877558 -0.85468892 -0.58722251  1.55250879 -0.4534893\n",
      "  0.08144352  0.08144352  0.61637635  1.28504238  1.686242   -0.4534893\n",
      "  1.28504238 -0.05228968  0.88384276  1.41877558  1.28504238 -0.18602289\n",
      " -0.72095571  0.21517673 -0.05228968  0.21517673  0.75010955  1.41877558\n",
      " -0.85468892  1.28504238  1.15130917 -1.25588854 -1.38962175  0.61637635\n",
      "  0.61637635 -1.65708816 -1.38962175 -1.25588854 -0.98842213 -1.12215533\n",
      "  0.08144352  0.61637635 -1.52335495 -0.3197561   1.01757597 -0.72095571\n",
      "  1.686242    1.686242    0.08144352 -0.3197561   0.34890993  1.55250879\n",
      " -0.05228968  0.48264314  0.48264314  0.34890993 -1.12215533 -0.18602289\n",
      " -1.52335495  0.75010955  0.75010955 -0.18602289  1.686242    0.21517673\n",
      "  0.61637635 -0.85468892  0.34890993 -0.72095571 -1.25588854 -0.18602289\n",
      " -1.52335495 -0.58722251 -0.58722251 -1.38962175  1.41877558 -0.72095571\n",
      " -1.38962175  0.48264314  0.21517673 -0.85468892  1.41877558 -1.38962175\n",
      " -0.3197561  -1.52335495 -0.4534893   1.01757597  1.01757597 -1.38962175\n",
      " -0.05228968  0.61637635  0.21517673  1.41877558 -0.18602289 -0.58722251\n",
      " -0.85468892 -0.3197561  -1.52335495 -1.38962175  1.15130917 -0.3197561\n",
      " -0.05228968  1.15130917  0.48264314  0.88384276  1.01757597 -0.3197561\n",
      "  0.48264314  1.28504238 -1.25588854 -0.98842213  0.61637635 -0.05228968\n",
      "  1.28504238  0.34890993 -0.05228968  0.34890993  0.08144352 -1.12215533\n",
      "  0.88384276  0.21517673 -1.65708816 -0.3197561  -1.25588854  0.34890993\n",
      " -1.65708816 -0.72095571  1.15130917  1.686242   -1.12215533 -0.58722251\n",
      " -0.58722251 -0.4534893  -1.52335495  1.15130917 -1.25588854 -1.65708816\n",
      "  1.15130917 -1.52335495 -0.05228968 -0.4534893 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[:, numerical_cols] = scaler.fit_transform(X.loc[:, numerical_cols])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.49\n",
      "R² Score: 99.9761\n",
      "✅ Model and scaler have been saved!\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv(\"blinkit_dynamic_pricing_1000_samples.csv\")\n",
    "\n",
    "# # Clean price columns by removing the \"₹\" symbol and converting to float\n",
    "# df[\"Base Price\"] = df[\"Base Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "# df[\"Competitor Price\"] = df[\"Competitor Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "# df[\"Optimized Price\"] = df[\"Optimized Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "\n",
    "# # Encode categorical variables (Demand, Supply)\n",
    "# # encoder = LabelEncoder()\n",
    "# # df[\"Demand\"] = encoder.fit_transform(df[\"Demand\"])   # e.g., High -> 2, Medium -> 1, Low -> 0\n",
    "# # df[\"Supply\"] = encoder.fit_transform(df[\"Supply\"])\n",
    "\n",
    "# # Define features (X) and target (y)\n",
    "# X = df[[\"Base Price\", \"Competitor Price\", \"Demand\", \"Supply\", \"Expiry Days\"]]\n",
    "# y = df[\"Optimized Price\"]\n",
    "\n",
    "# # Normalize numerical features using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X[[\"Base Price\", \"Competitor Price\", \"Expiry Days\"]] = scaler.fit_transform(X[[\"Base Price\", \"Competitor Price\", \"Expiry Days\"]])\n",
    "\n",
    "# # Split dataset into training and testing sets (80% train, 20% test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train the XGBoost Regressor\n",
    "# xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "# print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "# print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"blinkit_dynamic_pricing_1000_samples.csv\")\n",
    "\n",
    "# Clean price columns by removing the \"₹\" symbol and converting to float\n",
    "df[\"Base Price\"] = df[\"Base Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "df[\"Competitor Price\"] = df[\"Competitor Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "df[\"Optimized Price\"] = df[\"Optimized Price\"].replace({'₹': ''}, regex=True).astype(float)\n",
    "\n",
    "# For this example, we assume Demand and Supply columns are already numeric.\n",
    "# If they are categorical, you would need to encode them.\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[[\"Base Price\", \"Competitor Price\", \"Demand\", \"Supply\", \"Expiry Days\"]]\n",
    "y = df[\"Optimized Price\"]\n",
    "\n",
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = [\"Base Price\", \"Competitor Price\", \"Expiry Days\"]\n",
    "X.loc[:, numerical_cols] = scaler.fit_transform(X.loc[:, numerical_cols])\n",
    "\n",
    "# Optionally, save the scaler for future predictions\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Save the trained model to a pickle file for later use\n",
    "with open(\"xgb_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "print(\"✅ Model and scaler have been saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(new_sample)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Assume that 'encoder' and 'scaler' are already fitted on your training data.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# For example:\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# encoder = LabelEncoder() and then fitted on the 'Demand' and 'Supply' columns in your training set.\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;66;03m# and then fitted on the numeric columns.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Encode categorical variables\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# new_df[\"Demand\"] = encoder.transform(new_df[\"Demand\"])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# new_df[\"Supply\"] = encoder.transform(new_df[\"Supply\"])\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Scale numerical features\u001b[39;00m\n\u001b[0;32m     24\u001b[0m new_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompetitor Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpiry Days\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m     25\u001b[0m     new_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompetitor Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpiry Days\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     26\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example new input data (replace these values with your actual new sample)\n",
    "new_sample = {\n",
    "    \"Base Price\": [27],\n",
    "    \"Competitor Price\": [30],\n",
    "    \"Demand\": [1],      # Categorical input\n",
    "    \"Supply\": [2],    # Categorical input\n",
    "    \"Expiry Days\": [8]\n",
    "}\n",
    "new_df = pd.DataFrame(new_sample)\n",
    "\n",
    "# Assume that 'encoder' and 'scaler' are already fitted on your training data.\n",
    "# For example:\n",
    "# encoder = LabelEncoder() and then fitted on the 'Demand' and 'Supply' columns in your training set.\n",
    "scaler = StandardScaler()# and then fitted on the numeric columns.\n",
    "\n",
    "# Encode categorical variables\n",
    "# new_df[\"Demand\"] = encoder.transform(new_df[\"Demand\"])\n",
    "# new_df[\"Supply\"] = encoder.transform(new_df[\"Supply\"])\n",
    "\n",
    "# Scale numerical features\n",
    "new_df[[\"Base Price\", \"Competitor Price\", \"Expiry Days\"]] = scaler.transform(\n",
    "    new_df[[\"Base Price\", \"Competitor Price\", \"Expiry Days\"]]\n",
    ")\n",
    "\n",
    "# Predict using your trained XGBoost model (xgb_model)\n",
    "predicted_price = xgb_model.predict(new_df)[0]\n",
    "print(f\"Predicted Optimized Price: {predicted_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgb_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Product: Lifebuoy Handwash 250ml (Similarity Score: 36.62)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the CLIP model and its preprocessing function\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# List of product names (your catalog)\n",
    "product_names = [\n",
    "    \"Amul Milk 1L\", \"Aashirvaad Atta 5kg\", \"Parle-G Biscuits\", \"Maggi Noodles (Pack of 2)\", \"Nestle Coffee 200g\",\n",
    "    \"Bournvita 500g\", \"Haldiram Namkeen 250g\", \"Dairy Milk Chocolate\", \"Red Label Tea 250g\", \"Tata Salt 1kg\",\n",
    "    \"Kissan Ketchup 500g\", \"Everest Masala 100g\", \"Sprite 1.25L\", \"Coca-Cola 1.25L\", \"Pepsi 1.25L\",\n",
    "    \"Britannia Cheese Slices 200g\", \"Saffola Gold Oil 1L\", \"Fortune Basmati Rice 5kg\", \"Dettol Handwash 250ml\",\n",
    "    \"Colgate Toothpaste 200g\", \"Nivea Body Lotion 400ml\", \"Vim Dishwash Liquid 500ml\", \"Lizol Floor Cleaner 500ml\",\n",
    "    \"Surf Excel Matic 1kg\", \"Harpic Toilet Cleaner 500ml\", \"Sensodyne Toothpaste 100g\", \"Tide Detergent Powder 2kg\",\n",
    "    \"Dove Shampoo 650ml\", \"Pantene Conditioner 300ml\", \"Himalaya Face Wash 100ml\", \"Lifebuoy Handwash 250ml\",\n",
    "    \"Patanjali Aloe Vera Gel 150ml\", \"Horlicks Health Drink 500g\", \"Complan Nutrition 1kg\", \"Boost 500g\",\n",
    "    \"Quaker Oats 1kg\", \"Kellogg’s Corn Flakes 1kg\", \"Sundrop Peanut Butter 500g\", \"Nutella 350g\", \"Mother Dairy Paneer 200g\",\n",
    "    \"Britannia Rusk 300g\", \"Lay’s Potato Chips 90g\", \"Bingo Mad Angles 80g\", \"Sunfeast Dark Fantasy 75g\",\n",
    "    \"Hide & Seek Fab Biscuits\", \"Good Day Butter Cookies\", \"Perk Chocolate\", \"5 Star Chocolate\", \"KitKat Chocolate\",\n",
    "    \"Cadbury Silk\", \"Toblerone Chocolate\", \"Kinder Joy\", \"Kissan Mixed Fruit Jam 500g\", \"Sundrop Lite Oil 1L\",\n",
    "    \"Fortune Mustard Oil 1L\", \"Tata Tea Gold 250g\", \"Bru Coffee 200g\", \"Borges Olive Oil 500ml\", \"Dabur Honey 500g\",\n",
    "    \"Patanjali Cow Ghee 1L\", \"Gits Gulab Jamun Mix 200g\", \"MTR Instant Upma 200g\", \"Kellogg’s Muesli 500g\",\n",
    "    \"Weikfield Baking Powder 100g\", \"Weikfield Custard Powder 100g\", \"Tata Sampann Dal 1kg\", \"Chana Dal 1kg\",\n",
    "    \"Arhar Dal 1kg\", \"Rajma 1kg\", \"Kabuli Chana 1kg\", \"Moong Dal 1kg\", \"Whole Wheat Flour 5kg\", \"Gram Flour 1kg\",\n",
    "    \"Sugar 1kg\", \"Rock Salt 1kg\", \"Cooking Soda 100g\", \"MTR Rasam Powder 100g\", \"Everest Garam Masala 100g\",\n",
    "    \"MDH Chicken Masala 100g\", \"Everest Pav Bhaji Masala 100g\", \"Catch Chat Masala 100g\", \"Garam Masala 100g\",\n",
    "    \"Schezwan Chutney 250g\", \"Tomato Ketchup 1kg\", \"Soy Sauce 500ml\", \"Coconut Oil 1L\", \"Groundnut Oil 1L\"\n",
    "]\n",
    "\n",
    "# Compute text embeddings for all product names\n",
    "text_inputs = clip.tokenize(product_names).to(device)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "# Normalize text features\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "def predict_product_from_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "    # Normalize image features\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    # Compute cosine similarity between image and each product text embedding\n",
    "    similarity = (100.0 * image_features @ text_features.T).cpu().numpy()\n",
    "    best_idx = np.argmax(similarity)\n",
    "    \n",
    "    return product_names[best_idx], similarity[0][best_idx]\n",
    "\n",
    "# Example usage: Provide a path to a sample product image\n",
    "image_path = \"Nest.jpeg\"  # Replace with your actual image file\n",
    "predicted_product, sim_score = predict_product_from_image(image_path)\n",
    "print(f\"Predicted Product: {predicted_product} (Similarity Score: {sim_score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
